---
title: 'LSTM 네트워크의 이해'
date: '2017-1-4 10:00'
layout: post
published: true
---

> 이 문서의 원문은 [여기](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)에서 확인할 수 있습니다. 꼼꼼히 읽어보기 위해서 번역합니다.

### LSTM 네트워크의 이해

#### Recurrent Neural Networks

당신은 매 초마다 새로운 생각을 시작하는 것은 아니다. 이 글을 읽는 동안 당신은 이전 단어의 이해에 기반을 두어 단어들을 이해한다. 즉 당신은 모든 생각을 던져 버리고 새로운 생각을 시작하지는 않는다는 것이다. 그러므로 당신의 생각은 지속성을 가지고 있다. 

전통적 신경망은 이것을 할 수 없으며, 이는 주요한 결점인 것 처럼 보인다. 예를 들자면, 영화를 관람할때 매 시간마다 어떤 종류의 이벤트가 발생하는지를 분류하려고 한다고 상상해 보자. 전통적인 뉴럴네트워크가 어떻게 영화의 이전 사건에 대한 추론을 사용하여 나중에 알려줄 (분류할 수) 수 있는지 불분명하다.

재귀신경망은 이 문제를 처리할 수 있다. 재귀신경망들은 내부에 피드백을 가지고 있으며, 그로인해 정보가 지속성을 가지도록 할수 있다.

![](https://www.dropbox.com/s/3cxzh6z34utx9qw/RNN-rolled.png?dl=1){:height="200px" .center-image}

**루프를 가지고 있는 재귀신경망**

위 다이어그램에서, 신경망 묶음 $$A$$는 입력 $$X_t$$를 받아들이고 $$h_t$$를 출력으로 내보낸다. 여기서 루프는 정보가 네트워크의 하나의 단계로부터 네트워크의 다음으로 통과하도록 허용한다.

이러한 루프들은 재귀신경망을 다소 신비하게 보이도록 한다. 반면, 조금 더 생각해보면, 보통의 뉴럴네트워크와 완전히 다르지는 않다는 것을 알게 된다. 재귀신경망은 동일한 네트워크의 여러 복사본으로 생각할수 있으며 각각은 후임자 네트워크에게 메시지를 전달한다. 루프를 푼다는 어떻게 될지 생각해 보자: 










